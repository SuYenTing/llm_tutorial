{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61133469",
   "metadata": {},
   "source": [
    "## LangChain範例-對話(Chat)\n",
    "2025/06/29 蘇彥庭"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042172b",
   "metadata": {},
   "source": [
    "1. 單輪對話(Single-turn Chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c7677ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是 Gemma，一個由 Google DeepMind 訓練的大型語言模型。我是一個開放權務的大型語言模型，可以接收文字和圖片作為輸入，並以文本生成回答你。\n",
      "\n",
      "簡單來說，我是一個 AI 助手，可以幫你寫作，翻譯，回答問題，以及進行很多其他的事情。\n",
      "\n",
      "你有什么想和我聊的嗎？ 😊\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model = init_chat_model(\"gemma3:1b\", model_provider=\"ollama\")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\"你是誰?\"),\n",
    "]\n",
    "\n",
    "res = model.invoke(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca32b89",
   "metadata": {},
   "source": [
    "2. 系統訊息控制(System Message Control)\n",
    "* SystemMessage\n",
    "    * 用途：提供系統角色設定或對模型行為的指示。\n",
    "    * 常見用法：用來告訴模型應該扮演什麼樣的角色或遵循哪些規則。\n",
    "* HumanMessage\n",
    "    * 用途：模擬使用者的輸入。\n",
    "    * 常見用法：用來傳遞使用者的問題或請求。\n",
    "* AIMessage\n",
    "    * 用途：模擬 AI 的回應。\n",
    "    * 常見用法：用來記錄對話中 AI 所回覆的內容，讓後續對話有上下文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3bd17f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are...? \n",
      "\n",
      "It’s a very common and polite way to say “Who are you?” in Chinese. 😊 \n",
      "\n",
      "It literally translates to “Who are you?” but it’s often used as a greeting or a casual way to ask someone’s name. \n",
      "\n",
      "Let me know if you’d like me to translate a specific phrase or sentence!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model = init_chat_model(\"gemma3:1b\", model_provider=\"ollama\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from Chinese into English\"),\n",
    "    HumanMessage(\"你是誰?\"),\n",
    "]\n",
    "\n",
    "res = model.invoke(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc2188",
   "metadata": {},
   "source": [
    "3 具記憶的多輪對話(Multi-turn Chat with Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcacd69f",
   "metadata": {},
   "source": [
    "3.1 多輪對話無記憶性範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26f33505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 第1次回答 ----------\n",
      "\n",
      "好的，王小明，我记住了。 😊\n",
      "\n",
      "\n",
      "---------- 第2次回答 ----------\n",
      "\n",
      "我是一個大型語言模型，沒有名字。我是由 Google 開發的。你可以叫我“AI”或“助手”。 \n",
      "\n",
      "你是在用什麼樣的程式或工具與我互動呢？😊\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "model = init_chat_model(\"gemma3:1b\", model_provider=\"ollama\")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"我叫做王小明，請你記住我的名字!\"),\n",
    "]\n",
    "\n",
    "res = model.invoke(messages)\n",
    "\n",
    "print(\"\\n---------- 第1次回答 ----------\\n\")\n",
    "print(res.content)\n",
    "\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"請問我叫做什麼名字?\")\n",
    "]\n",
    "\n",
    "res = model.invoke(messages)\n",
    "\n",
    "print(\"\\n---------- 第2次回答 ----------\\n\")\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab98d2",
   "metadata": {},
   "source": [
    "3.2 對話具記憶性範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99689e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你叫做小明。😊\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "model = init_chat_model(\"gemma3:1b\", model_provider=\"ollama\")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"我叫做王小明，請你記住我的名字!\"),\n",
    "    AIMessage(content=\"好，王小明，我記住你！\"),  # 模擬 AI 回應 幫助模型記住前一輪內容\n",
    "    HumanMessage(content=\"請問我叫做什麼名字?\"),  # 新一輪輸入\n",
    "]\n",
    "\n",
    "res = model.invoke(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f176c600",
   "metadata": {},
   "source": [
    "3.3 用 ConversationBufferMemory 建立帶記憶的 Chat 流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75de1dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 第1次 ----------\n",
      "\n",
      "好，王小明，我記住你！ 😊\n",
      "\n",
      "\n",
      "---------- 第2次 ----------\n",
      "\n",
      "你叫做小明，正確！ 你是小明嗎？\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 建立 Ollama 模型\n",
    "llm = init_chat_model(\"gemma3:1b\", model_provider=\"ollama\")\n",
    "\n",
    "# 建立記憶體\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"history\",\n",
    ")\n",
    "\n",
    "# 手動模擬對話輪次\n",
    "def ask(input_text):\n",
    "    # 載入記憶訊息\n",
    "    history = memory.chat_memory.messages\n",
    "    # 加上當前人類輸入\n",
    "    messages = history + [HumanMessage(content=input_text)]\n",
    "    # 呼叫模型\n",
    "    response = llm.invoke(messages)\n",
    "    # 將新對話加入記憶\n",
    "    memory.chat_memory.add_user_message(input_text)\n",
    "    memory.chat_memory.add_ai_message(response.content)\n",
    "    return response.content\n",
    "\n",
    "# 測試\n",
    "print(\"\\n---------- 第1次 ----------\\n\")\n",
    "print(ask(\"我叫做王小明，請你記住我的名字!\"))\n",
    "\n",
    "print(\"\\n---------- 第2次 ----------\\n\")\n",
    "print(ask(\"請問我叫做什麼名字?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53813750",
   "metadata": {},
   "source": [
    "3.4 利用 Streamlit 快速搭一個對話服務\n",
    "\n",
    "程式已寫好在`chat_app.py`，請執行`streamlit run chat_app.py`指令。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
