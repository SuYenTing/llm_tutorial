# LangChainæ­é…streamlitç¯„ä¾‹
# ç¨‹å¼åŸ·è¡ŒæŒ‡ä»¤ `streamlit run chat_app.py``
import streamlit as st
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage
from langchain.memory import ConversationBufferMemory

# åˆå§‹åŒ–æ¨¡å‹
@st.cache_resource
def get_model():
    return init_chat_model("gemma3:1b", model_provider="ollama")

llm = get_model()

# åˆå§‹åŒ–è¨˜æ†¶é«”
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(
        return_messages=True,
        memory_key="history",
    )

# å°è©±å‡½å¼
def ask(input_text):
    memory = st.session_state.memory
    history = memory.chat_memory.messages
    messages = history + [HumanMessage(content=input_text)]
    response = llm.invoke(messages)
    memory.chat_memory.add_user_message(input_text)
    memory.chat_memory.add_ai_message(response.content)
    return response.content

# Streamlit ä»‹é¢
st.title("ğŸ’¬ LangChain + Ollama Chatbot")

# é¡¯ç¤ºå°è©±æ­·å²
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

for i, (user, bot) in enumerate(st.session_state.chat_history):
    st.markdown(f"**ğŸ§‘ ä½ :** {user}")
    st.markdown(f"**ğŸ¤– AI:** {bot}")

# è¼¸å…¥æ¡†
with st.form("chat_form", clear_on_submit=True):
    user_input = st.text_input("è«‹è¼¸å…¥ä½ çš„è¨Šæ¯ï¼š", key="input")
    submitted = st.form_submit_button("é€å‡º")
    if submitted and user_input:
        response = ask(user_input)
        st.session_state.chat_history.append((user_input, response))
        st.rerun()
